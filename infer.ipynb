{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/mmdet3d/evaluation/functional/kitti_utils/eval.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def get_thresholds(scores: np.ndarray, num_gt, num_sample_pts=41):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import supervisely as sly\n",
    "from mmengine.config import Config\n",
    "from mmdet3d.apis import LidarDet3DInferencer\n",
    "from src.tests.extract_weights_url import find_weights_url\n",
    "from src.sly_utils import download_point_cloud, upload_point_cloud\n",
    "from src.inference.pcd_inferencer import PcdDet3DInferencer\n",
    "from src.inference.functional import create_sly_annotation, up_bbox3d, filter_by_confidence\n",
    "from src.pcd_utils import convert_bin_to_pcd\n",
    "\n",
    "\n",
    "# globals    \n",
    "api = sly.Api()\n",
    "project_id = 32768\n",
    "dataset_id = 81541\n",
    "project_meta = sly.ProjectMeta.from_json(api.project.get_meta(project_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_pth_weights():\n",
    "    base_path = \"app_data/work_dir/\"\n",
    "    weights = [os.path.join(base_path, f) for f in os.listdir(base_path) if f.endswith(\".pth\")]\n",
    "    return max(weights, key=os.path.getctime)\n",
    "\n",
    "def get_last_config():\n",
    "    base_path = \"app_data/work_dir/\"\n",
    "    # get last dir in work_dir by name\n",
    "    dirs = [os.path.join(base_path, f) for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]\n",
    "    dir = sorted(dirs)[-1]\n",
    "    config = os.path.join(dir, \"vis_data\", \"config.py\")\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_url:  app_data/work_dir/epoch_40.pth\n",
      "cfg_model:  app_data/work_dir/20240108_001510/vis_data/config.py\n",
      "weights_url created:  2024-01-08 00:28:10.092466\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "weights_url = \"app_data/work_dir/epoch_10-pointpillars.pth\"\n",
    "cfg_model = \"app_data/work_dir/20231215_125044-pointpillars/vis_data/config.py\"\n",
    "\n",
    "weights_url = \"app_data/work_dir/epoch_20-centerpoint.pth\"\n",
    "cfg_model = \"app_data/work_dir/20231214_142029-centerpoint/vis_data/config.py\"\n",
    "\n",
    "weights_url = get_last_pth_weights()\n",
    "cfg_model = get_last_config()\n",
    "\n",
    "print(\"weights_url: \", weights_url)\n",
    "print(\"cfg_model: \", cfg_model)\n",
    "\n",
    "import datetime\n",
    "time = datetime.datetime.fromtimestamp(os.path.getctime(weights_url))\n",
    "print(\"weights_url created: \", time)\n",
    "\n",
    "# model_index = \"mmdetection3d/model-index.yml\"\n",
    "# weights_url = find_weights_url(model_index, re.sub(\"_custom.*\\.py\", \".py\", cfg_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import projects\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"mmdetection3d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be2bb0594664c4a89a45eb4d91cf25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model class names: ['car', 'pedestrian', 'truck']\n",
      "Loads checkpoint by local backend from path: app_data/work_dir/epoch_40.pth\n",
      "self.METAINFO['classes']=['car', 'pedestrian', 'truck'], self.label_mapping={0: 0, 1: 1, 2: 2, -1: -1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     inferencer \u001b[38;5;241m=\u001b[39m PcdDet3DInferencer(cfg_model, weights_url, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m \u001b[43minferencer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpcd_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_save_vis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m predictions \u001b[38;5;241m=\u001b[39m results_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m bboxes_3d \u001b[38;5;241m=\u001b[39m predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbboxes_3d\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmdet3d/apis/inferencers/base_3d_inferencer.py:210\u001b[0m, in \u001b[0;36mBase3DInferencer.__call__\u001b[0;34m(self, inputs, batch_size, return_datasamples, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    209\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisualization\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m (track(inputs, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInference\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    211\u001b[0m              \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress \u001b[38;5;28;01melse\u001b[39;00m inputs):\n\u001b[1;32m    212\u001b[0m     preds\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_kwargs))\n\u001b[1;32m    213\u001b[0m     visualization \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisualize(ori_inputs, preds,\n\u001b[1;32m    214\u001b[0m                                    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvisualize_kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/rich/progress.py:168\u001b[0m, in \u001b[0;36mtrack\u001b[0;34m(sequence, description, total, auto_refresh, console, transient, get_time, refresh_per_second, style, complete_style, finished_style, pulse_style, update_period, disable, show_speed)\u001b[0m\n\u001b[1;32m    157\u001b[0m progress \u001b[38;5;241m=\u001b[39m Progress(\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;241m*\u001b[39mcolumns,\n\u001b[1;32m    159\u001b[0m     auto_refresh\u001b[38;5;241m=\u001b[39mauto_refresh,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m progress:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m progress\u001b[38;5;241m.\u001b[39mtrack(\n\u001b[1;32m    169\u001b[0m         sequence, total\u001b[38;5;241m=\u001b[39mtotal, description\u001b[38;5;241m=\u001b[39mdescription, update_period\u001b[38;5;241m=\u001b[39mupdate_period\n\u001b[1;32m    170\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/rich/progress.py:1210\u001b[0m, in \u001b[0;36mProgress.track\u001b[0;34m(self, sequence, total, task_id, description, update_period)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlive\u001b[38;5;241m.\u001b[39mauto_refresh:\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _TrackThread(\u001b[38;5;28mself\u001b[39m, task_id, update_period) \u001b[38;5;28;01mas\u001b[39;00m track_thread:\n\u001b[0;32m-> 1210\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m sequence:\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m value\n\u001b[1;32m   1212\u001b[0m             track_thread\u001b[38;5;241m.\u001b[39mcompleted \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmengine/infer/infer.py:291\u001b[0m, in \u001b[0;36mBaseInferencer.preprocess\u001b[0;34m(self, inputs, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Process the inputs into a model-feedable format.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03mCustomize your preprocess by overriding this method. Preprocess should\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    Any: Data processed by the ``pipeline`` and ``collate_fn``.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m chunked_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_chunk_data(\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline, inputs), batch_size)\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn, chunked_data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmengine/infer/infer.py:588\u001b[0m, in \u001b[0;36mBaseInferencer._get_chunk_data\u001b[0;34m(self, inputs, chunk_size)\u001b[0m\n\u001b[1;32m    586\u001b[0m chunk_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(chunk_size):\n\u001b[0;32m--> 588\u001b[0m     processed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     chunk_data\u001b[38;5;241m.\u001b[39mappend(processed_data)\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m chunk_data\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmengine/dataset/base_dataset.py:60\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m   dict: Transformed data.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# The transform will return None when it failed to load images or\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# cannot find suitable augmentation parameters to augment the data.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Here we simply return None if the transform returns None and the\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# dataset will handle it by randomly selecting another data sample.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/transforms/base.py:12\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m              results: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[Dict, Tuple[List, List]]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmdet3d/datasets/transforms/transforms_3d.py:935\u001b[0m, in \u001b[0;36mPointsRangeFilter.transform\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dict: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    926\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform function to filter points by the range.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03m        and 'pts_semantic_mask' keys are updated in the result dict.\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 935\u001b[0m     points \u001b[38;5;241m=\u001b[39m \u001b[43minput_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpoints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    936\u001b[0m     points_mask \u001b[38;5;241m=\u001b[39m points\u001b[38;5;241m.\u001b[39min_range_3d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpcd_range)\n\u001b[1;32m    937\u001b[0m     clean_points \u001b[38;5;241m=\u001b[39m points[points_mask]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# 4 cars\n",
    "# pcd_path = \"app_data/lyft/LYFT/pointcloud/host-a005_lidar1_1231201454801395736.pcd\"\n",
    "# many cars\n",
    "pcd_path = \"app_data/lyft/LYFT/pointcloud/host-a005_lidar1_1231201437602160096.pcd\"\n",
    "\n",
    "_, ext = os.path.splitext(pcd_path)\n",
    "is_bin = ext == \".bin\"\n",
    "\n",
    "# Make config\n",
    "# loading existed 'cfg_model' is unsafe, because of inappropriate pipelines\n",
    "cfg = Config.fromfile(cfg_model)\n",
    "model_class_names = cfg.class_names\n",
    "print(f\"Model class names: {model_class_names}\")\n",
    "\n",
    "# add classes to project meta\n",
    "need_update = False\n",
    "for class_name in model_class_names:\n",
    "    if project_meta.get_obj_class(class_name) is None:\n",
    "        from supervisely.geometry.cuboid_3d import Cuboid3d\n",
    "        project_meta = project_meta.add_obj_class(sly.ObjClass(class_name, Cuboid3d))\n",
    "        print(f\"Added class {class_name} to project meta.\")\n",
    "        need_update = True\n",
    "if need_update:\n",
    "    api.project.update_meta(project_id, project_meta.to_json())\n",
    "    api.project.pull_meta_ids(project_id, project_meta)\n",
    "\n",
    "# Inference\n",
    "if is_bin:\n",
    "    inferencer = LidarDet3DInferencer(cfg_model, weights_url, device='cuda:0')\n",
    "else:\n",
    "    inferencer = PcdDet3DInferencer(cfg_model, weights_url, device='cuda:0')\n",
    "\n",
    "results_dict = inferencer(inputs=dict(points=pcd_path), no_save_vis=True)\n",
    "\n",
    "predictions = results_dict['predictions'][0]\n",
    "bboxes_3d = predictions['bboxes_3d']\n",
    "labels_3d = predictions['labels_3d']\n",
    "scores_3d = predictions['scores_3d']\n",
    "bboxes_3d, labels_3d, scores_3d = filter_by_confidence(bboxes_3d, labels_3d, scores_3d, threshold=0.45)\n",
    "bboxes_3d = [up_bbox3d(bbox3d) for bbox3d in bboxes_3d]\n",
    "\n",
    "# Create annotation\n",
    "ann = create_sly_annotation(bboxes_3d, labels_3d, model_class_names, project_meta)\n",
    "\n",
    "# Upload pcd\n",
    "if is_bin:\n",
    "    convert_bin_to_pcd(pcd_path, \"tmp.pcd\")\n",
    "    pcd_path = \"tmp.pcd\"\n",
    "name = \"tmp_infer_\"+sly.rand_str(8)+\".pcd\"\n",
    "pcd_info = upload_point_cloud(api, dataset_id, pcd_path, name=name)\n",
    "\n",
    "# Upload annotation\n",
    "pcd_id = pcd_info.id\n",
    "api.pointcloud.annotation.append(pcd_id, ann)\n",
    "\n",
    "print(name)\n",
    "print(f\"https://dev.supervise.ly/app/point-clouds/?datasetId={dataset_id}&pointCloudId={pcd_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    <src.inference.pcd_loader.PCDLoader object at 0x7fc749576d90>\n",
       "    MultiScaleFlipAug3D(transforms=Compose(\n",
       "    GlobalRotScaleTrans(rot_range=[0, 0], scale_ratio_range=[1.0, 1.0], translation_std=[0, 0, 0], shift_height=False)\n",
       "    RandomFlip3D(sync_2d=True, flip_ratio_bev_vertical=0.0)\n",
       "    PointsRangeFilter(point_cloud_range=[0.0, -10.0, -3.0, 10.399999618530273, 10.0, 1.0])\n",
       "), img_scale=[(1333, 600)], flip=False, pts_scale_ratio=[1.0], flip_direction=['horizontal'])\n",
       "    PointsRangeFilter(point_cloud_range=[0.0, -10.0, -3.0, 10.399999618530273, 10.0, 1.0])\n",
       "    Pack3DDetInputs(keys=['points'])(meta_keys=('img_path', 'ori_shape', 'img_shape', 'lidar2img', 'depth2img', 'cam2img', 'pad_shape', 'scale_factor', 'flip', 'pcd_horizontal_flip', 'pcd_vertical_flip', 'box_mode_3d', 'box_type_3d', 'img_norm_cfg', 'num_pts_feats', 'pcd_trans', 'sample_idx', 'pcd_scale_factor', 'pcd_rotation', 'pcd_rotation_angle', 'lidar_path', 'transformation_3d_flow', 'trans_mat', 'affine_aug', 'sweep_img_metas', 'ori_cam2img', 'cam2global', 'crop_offset', 'img_crop_offset', 'resize_img_shape', 'lidar2cam', 'ori_lidar2img', 'num_ref_frames', 'num_views', 'ego2global', 'axis_align_matrix'))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferencer._init_pipeline(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
